{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS Students Performance Data Analysis\n",
    "## Comprehensive Exploratory Data Analysis and Insights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m stats\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mwarnings\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style for better-looking plots\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and Load Data\n",
    "\n",
    "First, you'll need to:\n",
    "1. Install Kaggle CLI: `pip install kaggle`\n",
    "2. Download your Kaggle API token from https://www.kaggle.com/account\n",
    "3. Place it at ~/.kaggle/kaggle.json\n",
    "\n",
    "Or manually download the CSV from the Kaggle link and place it in the working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Check if file exists locally\n",
    "csv_file = 'cs_students.csv'\n",
    "data_path = Path(csv_file)\n",
    "\n",
    "if not data_path.exists():\n",
    "    print(\"Attempting to download from Kaggle...\")\n",
    "    try:\n",
    "        import subprocess\n",
    "        # Download using Kaggle CLI\n",
    "        subprocess.run(['kaggle', 'datasets', 'download', '-d', 'zahranusratt/cs-students-performance-dataset', \n",
    "                       '-p', '.', '--unzip'], check=True)\n",
    "        print(\"Dataset downloaded successfully!\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading: {e}\")\n",
    "        print(\"Please download manually from: https://www.kaggle.com/datasets/zahranusratt/cs-students-performance-dataset\")\n",
    "else:\n",
    "    print(f\"Found {csv_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "df = pd.read_csv('cs_students.csv')\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display basic information\n",
    "print(\"Dataset Information:\")\n",
    "print(f\"Total Records: {len(df)}\")\n",
    "print(f\"Total Features: {len(df.columns)}\")\n",
    "print(f\"\\nColumn Names and Types:\")\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical summary\n",
    "print(\"Statistical Summary:\")\n",
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing Values:\")\n",
    "missing = df.isnull().sum()\n",
    "missing_pct = (missing / len(df)) * 100\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing Count': missing,\n",
    "    'Percentage': missing_pct\n",
    "})\n",
    "print(missing_df[missing_df['Missing Count'] > 0])\n",
    "\n",
    "if missing.sum() == 0:\n",
    "    print(\"No missing values found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display all columns\n",
    "print(\"All Columns:\")\n",
    "for i, col in enumerate(df.columns, 1):\n",
    "    print(f\"{i}. {col}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical Features Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get numerical columns\n",
    "numerical_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "print(f\"Numerical columns: {numerical_cols}\")\n",
    "\n",
    "# Distribution of numerical features\n",
    "n_cols = len(numerical_cols)\n",
    "fig, axes = plt.subplots((n_cols + 1) // 2, 2, figsize=(14, 4 * ((n_cols + 1) // 2)))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, col in enumerate(numerical_cols):\n",
    "    axes[idx].hist(df[col], bins=30, color='steelblue', edgecolor='black', alpha=0.7)\n",
    "    axes[idx].set_title(f'Distribution of {col}', fontsize=12, fontweight='bold')\n",
    "    axes[idx].set_xlabel(col)\n",
    "    axes[idx].set_ylabel('Frequency')\n",
    "    axes[idx].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Remove extra subplots\n",
    "for idx in range(n_cols, len(axes)):\n",
    "    fig.delaxes(axes[idx])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "print(f\"\\nDisplayed distributions for {n_cols} numerical features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plots for numerical features\n",
    "fig, axes = plt.subplots((n_cols + 1) // 2, 2, figsize=(14, 4 * ((n_cols + 1) // 2)))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, col in enumerate(numerical_cols):\n",
    "    axes[idx].boxplot(df[col], vert=True)\n",
    "    axes[idx].set_title(f'Boxplot of {col}', fontsize=12, fontweight='bold')\n",
    "    axes[idx].set_ylabel(col)\n",
    "    axes[idx].grid(axis='y', alpha=0.3)\n",
    "\n",
    "for idx in range(n_cols, len(axes)):\n",
    "    fig.delaxes(axes[idx])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "print(\"Box plots displayed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical Features Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get categorical columns\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "print(f\"Categorical columns: {categorical_cols}\")\n",
    "\n",
    "if categorical_cols:\n",
    "    for col in categorical_cols:\n",
    "        print(f\"\\n{col}:\")\n",
    "        print(df[col].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize categorical features\n",
    "if categorical_cols:\n",
    "    fig, axes = plt.subplots((len(categorical_cols) + 1) // 2, 2, \n",
    "                             figsize=(14, 4 * ((len(categorical_cols) + 1) // 2)))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for idx, col in enumerate(categorical_cols):\n",
    "        df[col].value_counts().plot(kind='bar', ax=axes[idx], color='coral', edgecolor='black')\n",
    "        axes[idx].set_title(f'Distribution of {col}', fontsize=12, fontweight='bold')\n",
    "        axes[idx].set_xlabel(col)\n",
    "        axes[idx].set_ylabel('Count')\n",
    "        axes[idx].tick_params(axis='x', rotation=45)\n",
    "        axes[idx].grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    for idx in range(len(categorical_cols), len(axes)):\n",
    "        fig.delaxes(axes[idx])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(numerical_cols) > 1:\n",
    "    # Correlation matrix\n",
    "    corr_matrix = df[numerical_cols].corr()\n",
    "    \n",
    "    # Heatmap\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='coolwarm', \n",
    "                center=0, square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
    "    plt.title('Correlation Matrix of Numerical Features', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nTop Correlations (excluding 1.0):\")\n",
    "    # Get top correlations\n",
    "    corr_pairs = []\n",
    "    for i in range(len(corr_matrix.columns)):\n",
    "        for j in range(i+1, len(corr_matrix.columns)):\n",
    "            corr_pairs.append((\n",
    "                corr_matrix.columns[i],\n",
    "                corr_matrix.columns[j],\n",
    "                corr_matrix.iloc[i, j]\n",
    "            ))\n",
    "    \n",
    "    corr_pairs_sorted = sorted(corr_pairs, key=lambda x: abs(x[2]), reverse=True)[:10]\n",
    "    for col1, col2, corr in corr_pairs_sorted:\n",
    "        print(f\"{col1} <-> {col2}: {corr:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If there's a performance or grade column, analyze it\n",
    "print(\"Looking for performance-related columns...\")\n",
    "performance_cols = [col for col in df.columns if any(keyword in col.lower() \n",
    "                    for keyword in ['grade', 'score', 'gpa', 'performance', 'mark', 'final', 'result'])]\n",
    "\n",
    "if performance_cols:\n",
    "    print(f\"Found performance columns: {performance_cols}\")\n",
    "    \n",
    "    fig, axes = plt.subplots(1, len(performance_cols), figsize=(5*len(performance_cols), 5))\n",
    "    if len(performance_cols) == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for idx, col in enumerate(performance_cols):\n",
    "        axes[idx].hist(df[col], bins=30, color='green', alpha=0.7, edgecolor='black')\n",
    "        axes[idx].set_title(f'Distribution of {col}', fontsize=12, fontweight='bold')\n",
    "        axes[idx].set_xlabel(col)\n",
    "        axes[idx].set_ylabel('Frequency')\n",
    "        axes[idx].axvline(df[col].mean(), color='red', linestyle='--', label=f'Mean: {df[col].mean():.2f}')\n",
    "        axes[idx].axvline(df[col].median(), color='blue', linestyle='--', label=f'Median: {df[col].median():.2f}')\n",
    "        axes[idx].legend()\n",
    "        axes[idx].grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No specific performance columns found. Check data structure.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relationships Between Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot matrix for numerical features (if not too many)\n",
    "if len(numerical_cols) <= 6:\n",
    "    pd.plotting.scatter_matrix(df[numerical_cols], figsize=(12, 10), \n",
    "                               diagonal='hist', alpha=0.7)\n",
    "    plt.suptitle('Scatter Matrix of Numerical Features', fontsize=14, fontweight='bold', y=1.00)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(f\"Too many numerical features ({len(numerical_cols)}) for scatter matrix. Creating subset...\")\n",
    "    # Select first 6 most important numerical columns\n",
    "    subset_cols = numerical_cols[:6]\n",
    "    pd.plotting.scatter_matrix(df[subset_cols], figsize=(12, 10), \n",
    "                               diagonal='hist', alpha=0.7)\n",
    "    plt.suptitle('Scatter Matrix (First 6 Numerical Features)', fontsize=14, fontweight='bold', y=1.00)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate skewness and kurtosis for numerical features\n",
    "print(\"Skewness and Kurtosis Analysis:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "stats_df = pd.DataFrame({\n",
    "    'Mean': df[numerical_cols].mean(),\n",
    "    'Median': df[numerical_cols].median(),\n",
    "    'Std Dev': df[numerical_cols].std(),\n",
    "    'Skewness': df[numerical_cols].skew(),\n",
    "    'Kurtosis': df[numerical_cols].kurtosis()\n",
    "})\n",
    "\n",
    "print(stats_df.round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outlier detection using IQR method\n",
    "print(\"\\nOutlier Detection (IQR Method):\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "outlier_summary = {}\n",
    "for col in numerical_cols:\n",
    "    Q1 = df[col].quantile(0.25)\n",
    "    Q3 = df[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)]\n",
    "    outlier_summary[col] = {\n",
    "        'Count': len(outliers),\n",
    "        'Percentage': (len(outliers) / len(df)) * 100\n",
    "    }\n",
    "\n",
    "outlier_df = pd.DataFrame(outlier_summary).T\n",
    "outlier_df = outlier_df[outlier_df['Count'] > 0].sort_values('Count', ascending=False)\n",
    "\n",
    "if len(outlier_df) > 0:\n",
    "    print(outlier_df)\n",
    "else:\n",
    "    print(\"No significant outliers detected\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Findings Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"DATA ANALYSIS SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\n1. DATASET OVERVIEW:\")\n",
    "print(f\"   - Total Records: {len(df):,}\")\n",
    "print(f\"   - Total Features: {len(df.columns)}\")\n",
    "print(f\"   - Numerical Features: {len(numerical_cols)}\")\n",
    "print(f\"   - Categorical Features: {len(categorical_cols)}\")\n",
    "print(f\"   - Missing Values: {'None' if df.isnull().sum().sum() == 0 else df.isnull().sum().sum()}\")\n",
    "\n",
    "print(f\"\\n2. NUMERICAL FEATURES SUMMARY:\")\n",
    "for col in numerical_cols:\n",
    "    print(f\"   - {col}: Mean={df[col].mean():.2f}, Std={df[col].std():.2f}, \"\n",
    "          f\"Range=[{df[col].min():.2f}, {df[col].max():.2f}]\")\n",
    "\n",
    "if categorical_cols:\n",
    "    print(f\"\\n3. CATEGORICAL FEATURES:\")\n",
    "    for col in categorical_cols:\n",
    "        print(f\"   - {col}: {df[col].nunique()} unique values\")\n",
    "        print(f\"     Top 3: {dict(df[col].value_counts().head(3))}\")\n",
    "\n",
    "print(f\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommendations for Further Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"\n",
    "Suggestions for deeper analysis:\n",
    "\n",
    "1. PREDICTIVE MODELING:\n",
    "   - Build a regression model to predict student performance\n",
    "   - Use features like study hours, GPA, etc. as predictors\n",
    "\n",
    "2. CLUSTERING:\n",
    "   - Identify student groups with similar characteristics\n",
    "   - Use K-means or hierarchical clustering\n",
    "\n",
    "3. STATISTICAL TESTS:\n",
    "   - Perform ANOVA to compare performance across groups\n",
    "   - Chi-square tests for categorical relationships\n",
    "\n",
    "4. FEATURE ENGINEERING:\n",
    "   - Create derived features (e.g., study intensity ratios)\n",
    "   - Normalize features for modeling\n",
    "\n",
    "5. TIME SERIES ANALYSIS:\n",
    "   - If temporal data exists, analyze performance trends\n",
    "\n",
    "6. SEGMENTATION:\n",
    "   - Identify high/low performers\n",
    "   - Analyze characteristics of top students\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (torch)",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
